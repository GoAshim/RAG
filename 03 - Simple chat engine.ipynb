{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d015281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180a12a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variable containing the OpenAI API Key so we don't have to hardcode that here\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2ef80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI object with LLM\n",
    "# We are using 'gpt-4o-mini' because it's cost effective and capable enough to query on text\n",
    "# Refer https://platform.openai.com/docs/models/gpt-4o-mini for more info\n",
    "\n",
    "model = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d24c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# We will use the SimpleDirectoryReader from LlamaIndex to read the text file and store into Document object of LlamaIndex\n",
    "# SimpleDirectoryReader can read one or more files and supports various file types such as .csv, .docx, .pdf, and more.\n",
    "# Refer to https://github.com/run-llama/llama_index/blob/main/docs/docs/module_guides/loading/simpledirectoryreader.md\n",
    "\n",
    "docs = SimpleDirectoryReader(\"./data/txt/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d43eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The VectorStoreIndex in LlamaIndex helps to store, query, and manage vector embeddings efficiently in RAG workflows. \n",
    "# Refer https://github.com/run-llama/llama_index/blob/main/docs/docs/module_guides/indexing/vector_store_index.md for more.\n",
    "# Here we will create the in-memory vector store from the document we created above from the pdf file\n",
    "# Make sure to have credit available in OpenAI account, otherwise it will give error saying \"You exceeded your current quota\"\n",
    "\n",
    "vector = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa93bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The as_chat_engine helps making a conversation with data with multiple back-and-forth instead of a single question & answer.\n",
    "# Refer https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/ for more\n",
    "# For standalone question over data without keeping track of conversation history, we should use Query Engine instead\n",
    "# Create a chat engine from the vector store using the best mode\n",
    "# Refer to https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_best/ for different chat modes\n",
    "\n",
    "chat_engine = vector.as_chat_engine(chat_mode=\"best\", verbose=True, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84f8fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Who is Paul Graham?\n",
      "Condensed question: Who is Paul Graham?\n",
      "Agent: Paul Graham is a well-known computer scientist, entrepreneur, and essayist. He is particularly recognized for his work in the field of programming languages, having created the programming language Lisp and developed a dialect called Arc. Graham co-founded Viaweb, one of the first web-based applications, which allowed users to create online stores. This company was later acquired by Yahoo! and became Yahoo! Store.\n",
      "\n",
      "In addition to his technical contributions, Graham is also famous for his essays on various topics, including technology, startups, and life experiences. His essays often reflect on his personal journey in the tech industry and provide insights into entrepreneurship and innovation. He is also a co-founder of Y Combinator, a startup accelerator that has helped launch numerous successful companies. Graham's writing and ideas have had a significant impact on the startup ecosystem and the tech community at large.\n",
      "User: when did he found YC?\n",
      "Condensed question: When did Paul Graham found Y Combinator?\n",
      "Agent: Paul Graham co-founded Y Combinator (YC) in March 2005. The idea for YC emerged from his experiences and discussions with colleagues about how to better support startup founders. The first batch of startups funded by YC took place in the summer of 2005, which included notable companies like Reddit and Twitch.\n",
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "# Chat using the chat engine created above\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "    agent_response = chat_engine.chat(user_input)\n",
    "    print(f\"Agent: {agent_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
